#!/usr/bin/env python3
# -*- coding: utf-8 -*-
"""
–ü—Ä–∏–º–µ—Ä –ø–æ–ª–Ω–æ–≥–æ —Ä–∞–±–æ—á–µ–≥–æ –ø—Ä–æ—Ü–µ—Å—Å–∞ –ê–ò–° –£–î–ó

–î–µ–º–æ–Ω—Å—Ç—Ä–∏—Ä—É–µ—Ç:
1. –ó–∞–≥—Ä—É–∑–∫—É –∏ –ø–∞—Ä—Å–∏–Ω–≥ –¥–æ–∫—É–º–µ–Ω—Ç–∞—Ü–∏–∏
2. –ê–Ω–∞–ª–∏–∑ —Å –ø–æ–º–æ—â—å—é LLM
3. –§–æ—Ä–º–∏—Ä–æ–≤–∞–Ω–∏–µ –ø–∞–∫–µ—Ç–∞ –¥–æ–∫—É–º–µ–Ω—Ç–æ–≤
4. –ú–Ω–æ–≥–æ—ç—Ç–∞–ø–Ω—ã–π –∫–æ–Ω—Ç—Ä–æ–ª—å
5. –≠–∫—Å–ø–æ—Ä—Ç —Ä–µ–∑—É–ª—å—Ç–∞—Ç–∞
"""

import sys
from pathlib import Path
import json
from datetime import datetime

# –î–æ–±–∞–≤–ª—è–µ–º –ø—É—Ç—å –∫ –º–æ–¥—É–ª—è–º
sys.path.append(str(Path(__file__).parent.parent))

from src.utils import DocumentParserFactory, CacheManager, DocumentDeduplicator
from src.analyzer import DocumentAnalyzer


def main():
    """
    –ü–æ–ª–Ω—ã–π workflow –æ–±—Ä–∞–±–æ—Ç–∫–∏ –∑–∞–∫—É–ø–∫–∏
    """
    print("=" * 70)
    print("–ê–í–¢–û–ú–ê–¢–ò–ó–ò–†–û–í–ê–ù–ù–ê–Ø –°–ò–°–¢–ï–ú–ê –£–ü–†–ê–í–õ–ï–ù–ò–Ø –î–û–ö–£–ú–ï–ù–¢–ê–ú–ò –ó–ê–ö–£–ü–û–ö")
    print("=" * 70)
    print()
    
    # –®–∞–≥ 1: –ó–∞–≥—Ä—É–∑–∫–∞ –¥–æ–∫—É–º–µ–Ω—Ç–∞—Ü–∏–∏
    print("üìÑ –®–ê–ì 1: –ó–∞–≥—Ä—É–∑–∫–∞ –∑–∞–∫—É–ø–æ—á–Ω–æ–π –¥–æ–∫—É–º–µ–Ω—Ç–∞—Ü–∏–∏")
    print("-" * 70)
    
    doc_file = Path("example_procurement.pdf")
    
    if not doc_file.exists():
        print(f"‚ö†Ô∏è  –§–∞–π–ª {doc_file} –Ω–µ –Ω–∞–π–¥–µ–Ω")
        print("üí° –°–æ–∑–¥–∞–π—Ç–µ —Ç–µ—Å—Ç–æ–≤—ã–π —Ñ–∞–π–ª –∏–ª–∏ –∏—Å–ø–æ–ª—å–∑—É–π—Ç–µ —Å—É—â–µ—Å—Ç–≤—É—é—â–∏–π")
        return
    
    # –°–æ–∑–¥–∞–µ–º –ø–∞—Ä—Å–µ—Ä –∞–≤—Ç–æ–º–∞—Ç–∏—á–µ—Å–∫–∏
    parser = DocumentParserFactory.create_parser(
        doc_file,
        config={
            "use_ocr": True,
            "ocr_lang": "rus+eng",
            "extract_tables": True
        }
    )
    
    print(f"‚úÖ –í—ã–±—Ä–∞–Ω –ø–∞—Ä—Å–µ—Ä: {parser.__class__.__name__}")
    
    # –ü–∞—Ä—Å–∏–º –¥–æ–∫—É–º–µ–Ω—Ç
    print(f"‚è≥ –ü–∞—Ä—Å–∏–Ω–≥ –¥–æ–∫—É–º–µ–Ω—Ç–∞...")
    parse_result = parser.parse(doc_file)
    
    if not parse_result.is_success:
        print(f"‚ùå –û—à–∏–±–∫–∞ –ø–∞—Ä—Å–∏–Ω–≥–∞: {parse_result.errors}")
        return
    
    print(f"‚úÖ –ü–∞—Ä—Å–∏–Ω–≥ –∑–∞–≤–µ—Ä—à–µ–Ω:")
    print(f"   - –ò–∑–≤–ª–µ—á–µ–Ω–æ —Å–∏–º–≤–æ–ª–æ–≤: {parse_result.char_count}")
    print(f"   - –ò–∑–≤–ª–µ—á–µ–Ω–æ —Å–ª–æ–≤: {parse_result.word_count}")
    print(f"   - –ù–∞–π–¥–µ–Ω–æ —Ç–∞–±–ª–∏—Ü: {len(parse_result.tables)}")
    print(f"   - –í—Ä–µ–º—è –ø–∞—Ä—Å–∏–Ω–≥–∞: {parse_result.parse_time:.2f} —Å–µ–∫")
    print()
    
    # –®–∞–≥ 2: –ê–Ω–∞–ª–∏–∑ —Å –ø–æ–º–æ—â—å—é LLM
    print("ü§ñ –®–ê–ì 2: –ê–Ω–∞–ª–∏–∑ —Ç—Ä–µ–±–æ–≤–∞–Ω–∏–π —Å –ø–æ–º–æ—â—å—é LLM")
    print("-" * 70)
    
    # –ò–Ω–∏—Ü–∏–∞–ª–∏–∑–∞—Ü–∏—è –∞–Ω–∞–ª–∏–∑–∞—Ç–æ—Ä–∞
    analyzer = DocumentAnalyzer()
    
    # –ü—Ä–æ–≤–µ—Ä—è–µ–º –∫—ç—à
    cache_manager = CacheManager()
    cache_key = CacheManager.generate_key(parse_result.text)
    
    cached_result = cache_manager.get(cache_key)
    
    if cached_result:
        print("‚úÖ –ù–∞–π–¥–µ–Ω —Ä–µ–∑—É–ª—å—Ç–∞—Ç –≤ –∫—ç—à–µ")
        analysis_result = cached_result
    else:
        print("‚è≥ –ê–Ω–∞–ª–∏–∑ –¥–æ–∫—É–º–µ–Ω—Ç–∞—Ü–∏–∏ (–º–æ–∂–µ—Ç –∑–∞–Ω—è—Ç—å –¥–æ 30 —Å–µ–∫)...")
        
        try:
            analysis_result = analyzer.analyze(
                document_text=parse_result.text,
                provided_docs=[]
            )
            
            # –°–æ—Ö—Ä–∞–Ω—è–µ–º –≤ –∫—ç—à
            cache_manager.set(cache_key, analysis_result)
            
            print("‚úÖ –ê–Ω–∞–ª–∏–∑ –∑–∞–≤–µ—Ä—à–µ–Ω")
        except Exception as e:
            print(f"‚ùå –û—à–∏–±–∫–∞ –∞–Ω–∞–ª–∏–∑–∞: {e}")
            return
    
    # –î–µ–¥—É–ø–ª–∏–∫–∞—Ü–∏—è –Ω–∞–π–¥–µ–Ω–Ω—ã—Ö –¥–æ–∫—É–º–µ–Ω—Ç–æ–≤
    deduplicator = DocumentDeduplicator(similarity_threshold=0.85)
    required_docs = deduplicator.deduplicate(
        analysis_result.get("required_documents", [])
    )
    
    print(f"üìã –†–µ–∑—É–ª—å—Ç–∞—Ç—ã –∞–Ω–∞–ª–∏–∑–∞:")
    print(f"   - –ù–∞–π–¥–µ–Ω–æ –¥–æ–∫—É–º–µ–Ω—Ç–æ–≤: {len(analysis_result.get('required_documents', []))}")
    print(f"   - –ü–æ—Å–ª–µ –¥–µ–¥—É–ø–ª–∏–∫–∞—Ü–∏–∏: {len(required_docs)}")
    print(f"   - –û–±—è–∑–∞—Ç–µ–ª—å–Ω—ã—Ö: {sum(1 for d in required_docs if d.get('mandatory'))}")
    print(f"   - –û–ø—Ü–∏–æ–Ω–∞–ª—å–Ω—ã—Ö: {sum(1 for d in required_docs if not d.get('mandatory'))}")
    print()
    
    # –í—ã–≤–æ–¥–∏–º —Ç–æ–ø-5 –¥–æ–∫—É–º–µ–Ω—Ç–æ–≤
    print("üìÑ –¢–æ–ø-5 —Ç—Ä–µ–±—É–µ–º—ã—Ö –¥–æ–∫—É–º–µ–Ω—Ç–æ–≤:")
    for i, doc in enumerate(required_docs[:5], 1):
        mandatory_mark = "üî¥" if doc.get("mandatory") else "üü°"
        print(f"   {mandatory_mark} {i}. {doc.get('name')}")
        print(f"      –ö–∞—Ç–µ–≥–æ—Ä–∏—è: {doc.get('category')}")
        if doc.get('validity_requirements'):
            print(f"      –°—Ä–æ–∫ –¥–µ–π—Å—Ç–≤–∏—è: {doc.get('validity_requirements')}")
    print()
    
    # –®–∞–≥ 3: –°–≤–µ—Ä–∫–∞ –ø—Ä–µ–¥–æ—Å—Ç–∞–≤–ª–µ–Ω–Ω—ã—Ö –¥–æ–∫—É–º–µ–Ω—Ç–æ–≤
    print("‚úÖ –®–ê–ì 3: –°–≤–µ—Ä–∫–∞ –ø—Ä–µ–¥–æ—Å—Ç–∞–≤–ª–µ–Ω–Ω—ã—Ö –¥–æ–∫—É–º–µ–Ω—Ç–æ–≤")
    print("-" * 70)
    
    # –ü—Ä–∏–º–µ—Ä –ø—Ä–µ–¥–æ—Å—Ç–∞–≤–ª–µ–Ω–Ω—ã—Ö –¥–æ–∫—É–º–µ–Ω—Ç–æ–≤
    provided_documents = [
        "–í—ã–ø–∏—Å–∫–∞ –∏–∑ –ï–ì–†–Æ–õ –æ—Ç 10.01.2026",
        "–£—Å—Ç–∞–≤ –æ—Ä–≥–∞–Ω–∏–∑–∞—Ü–∏–∏",
        "–ë—É—Ö–≥–∞–ª—Ç–µ—Ä—Å–∫–∏–π –±–∞–ª–∞–Ω—Å –∑–∞ 2024 –≥–æ–¥",
    ]
    
    print("üì¶ –ü—Ä–µ–¥–æ—Å—Ç–∞–≤–ª–µ–Ω–Ω—ã–µ –¥–æ–∫—É–º–µ–Ω—Ç—ã:")
    for doc in provided_documents:
        print(f"   ‚úì {doc}")
    print()
    
    verification_result = analyzer.verify_documents(
        required=required_docs,
        provided=provided_documents
    )
    
    print(f"üìä –†–µ–∑—É–ª—å—Ç–∞—Ç —Å–≤–µ—Ä–∫–∏:")
    print(f"   - –ü–æ–ª–Ω–æ—Ç–∞ –∫–æ–º–ø–ª–µ–∫—Ç–∞: {verification_result['completeness_score']}%")
    print(f"   - –ü—Ä–µ–¥–æ—Å—Ç–∞–≤–ª–µ–Ω–æ: {len(verification_result['provided'])}")
    print(f"   - –ö—Ä–∏—Ç–∏—á–Ω—ã—Ö –Ω–µ–¥–æ—Å—Ç–∞–µ—Ç: {len(verification_result['missing_critical'])}")
    print(f"   - –û–ø—Ü–∏–æ–Ω–∞–ª—å–Ω—ã—Ö –Ω–µ–¥–æ—Å—Ç–∞–µ—Ç: {len(verification_result['missing_optional'])}")
    print()
    
    if verification_result['missing_critical']:
        print("‚ö†Ô∏è  –û—Ç—Å—É—Ç—Å—Ç–≤—É—é—Ç –∫—Ä–∏—Ç–∏—á–Ω—ã–µ –¥–æ–∫—É–º–µ–Ω—Ç—ã:")
        for doc_id in verification_result['missing_critical']:
            doc = next((d for d in required_docs if d['id'] == doc_id), None)
            if doc:
                print(f"   ‚ùå {doc['name']}")
        print()
    
    # –®–∞–≥ 4: –§–æ—Ä–º–∏—Ä–æ–≤–∞–Ω–∏–µ –∏—Ç–æ–≥–æ–≤–æ–≥–æ –æ—Ç—á–µ—Ç–∞
    print("üìä –®–ê–ì 4: –§–æ—Ä–º–∏—Ä–æ–≤–∞–Ω–∏–µ –∏—Ç–æ–≥–æ–≤–æ–≥–æ –æ—Ç—á–µ—Ç–∞")
    print("-" * 70)
    
    report = {
        "procurement_info": analysis_result.get("procurement_info", {}),
        "analysis_date": datetime.now().isoformat(),
        "documents_statistics": {
            "total_required": len(required_docs),
            "mandatory": sum(1 for d in required_docs if d.get('mandatory')),
            "optional": sum(1 for d in required_docs if not d.get('mandatory')),
            "provided": len(verification_result['provided']),
            "missing_critical": len(verification_result['missing_critical']),
            "missing_optional": len(verification_result['missing_optional']),
            "completeness_score": verification_result['completeness_score']
        },
        "required_documents": required_docs,
        "verification": verification_result,
        "readiness_status": "READY" if verification_result['completeness_score'] >= 100 else "NOT_READY"
    }
    
    # –°–æ—Ö—Ä–∞–Ω—è–µ–º –æ—Ç—á–µ—Ç
    output_dir = Path("output")
    output_dir.mkdir(exist_ok=True)
    
    report_file = output_dir / f"report_{datetime.now().strftime('%Y%m%d_%H%M%S')}.json"
    
    with open(report_file, 'w', encoding='utf-8') as f:
        json.dump(report, f, ensure_ascii=False, indent=2)
    
    print(f"‚úÖ –û—Ç—á–µ—Ç —Å–æ—Ö—Ä–∞–Ω–µ–Ω: {report_file}")
    print()
    
    # –§–∏–Ω–∞–ª—å–Ω—ã–π —Å—Ç–∞—Ç—É—Å
    print("=" * 70)
    if report['readiness_status'] == "READY":
        print("üéâ –ó–ê–Ø–í–ö–ê –ì–û–¢–û–í–ê –ö –ü–û–î–ê–ß–ï")
        print(f"   –ü–æ–ª–Ω–æ—Ç–∞ –∫–æ–º–ø–ª–µ–∫—Ç–∞: {verification_result['completeness_score']}%")
    else:
        print("‚ö†Ô∏è  –ó–ê–Ø–í–ö–ê –ù–ï –ì–û–¢–û–í–ê –ö –ü–û–î–ê–ß–ï")
        print(f"   –ü–æ–ª–Ω–æ—Ç–∞ –∫–æ–º–ø–ª–µ–∫—Ç–∞: {verification_result['completeness_score']}%")
        print(f"   –ù–µ–¥–æ—Å—Ç–∞–µ—Ç {len(verification_result['missing_critical'])} –∫—Ä–∏—Ç–∏—á–Ω—ã—Ö –¥–æ–∫—É–º–µ–Ω—Ç–æ–≤")
    print("=" * 70)


if __name__ == "__main__":
    main()
